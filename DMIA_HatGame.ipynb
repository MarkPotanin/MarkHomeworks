{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from collections import Counter\n",
    "import heapq\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import gensim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/MarkPotanin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed:  0 documents from 11314\n",
      "Processed:  500 documents from 11314\n",
      "Processed:  1000 documents from 11314\n",
      "Processed:  1500 documents from 11314\n",
      "Processed:  2000 documents from 11314\n",
      "Processed:  2500 documents from 11314\n",
      "Processed:  3000 documents from 11314\n",
      "Processed:  3500 documents from 11314\n",
      "Processed:  4000 documents from 11314\n",
      "Processed:  4500 documents from 11314\n",
      "Processed:  5000 documents from 11314\n",
      "Processed:  5500 documents from 11314\n",
      "Processed:  6000 documents from 11314\n",
      "Processed:  6500 documents from 11314\n",
      "Processed:  7000 documents from 11314\n",
      "Processed:  7500 documents from 11314\n",
      "Processed:  8000 documents from 11314\n",
      "Processed:  8500 documents from 11314\n",
      "Processed:  9000 documents from 11314\n",
      "Processed:  9500 documents from 11314\n",
      "Processed:  10000 documents from 11314\n",
      "Processed:  10500 documents from 11314\n",
      "Processed:  11000 documents from 11314\n"
     ]
    }
   ],
   "source": [
    "pured_documents = []\n",
    "for i, doc in enumerate(dataset.data):\n",
    "    tokens = gensim.utils.lemmatize(doc)\n",
    "    document = []\n",
    "    for token in tokens:\n",
    "        word = token.split('/')[0]\n",
    "        if word not in english_stopwords:\n",
    "            document.append(word)\n",
    "    pured_documents.append(document)    \n",
    "    if i % 500 == 0:\n",
    "        print 'Processed: ', i, 'documents from', len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(list(itertools.chain.from_iterable(pured_documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NltkHatPlayer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def guess(self, words):\n",
    "        candidates = Counter()\n",
    "        for word in words:\n",
    "            for w in self.explain(word)[:5]:\n",
    "                candidates[w] += 1\n",
    "        for word in words:\n",
    "            if word in candidates:\n",
    "                del candidates[word]\n",
    "        return [x for x, _ in candidates.most_common(len(candidates))]\n",
    "    \n",
    "    def explain(self, word):\n",
    "        return text._word_context_index.similar_words(word)\n",
    "    \n",
    "    def guess_result(self, position):\n",
    "        pass\n",
    "    \n",
    "    def explanation_result(self, position):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class mixed(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def merge_two_dicts(x, y):\n",
    "    \n",
    "        z = x.copy()\n",
    "        z.update(y)\n",
    "        return z\n",
    "    def guess(self, words):\n",
    "        candidates = Counter()\n",
    "        for word in words:\n",
    "            for w in self.explain(word)[:5]:\n",
    "                candidates[w] += 1\n",
    "        for word in words:\n",
    "            if word in candidates:\n",
    "                del candidates[word]\n",
    "        a=dict(model.most_similar(positive=words))\n",
    "        b=dict(candidates.most_common(len(candidates)))\n",
    "        c=merge_two_dicts(a,b)\n",
    "        \n",
    "        return sorted(c, key=c.get, reverse=True)\n",
    "    \n",
    "    def explain(self, word):\n",
    "        a=[x for x, _ in model.most_similar(positive=[word])]+text._word_context_index.similar_words(word)\n",
    "        return np.random.choice(a,len(a))\n",
    "    \n",
    "    def guess_result(self, position):\n",
    "        pass\n",
    "    \n",
    "    def explanation_result(self, position):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(pured_documents, size=100, window=5, min_count=5, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GensimHatPlayer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def guess(self, words):\n",
    "        return [x for x, _ in model.most_similar(positive=words)]\n",
    "    \n",
    "    def explain(self, word):\n",
    "        return [x for x, _ in model.most_similar(positive=[word])]\n",
    "    \n",
    "    def guess_result(self, position):\n",
    "        pass\n",
    "    \n",
    "    def explanation_result(self, position):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(d, key=.get, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_universe = model.vocab.keys()\n",
    "words_universe_set = set(model.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_score(player1, player2, word):\n",
    "    explanation = [x for x in player1.explain(word) if x in words_universe_set][:10]\n",
    "    exp_score = 0.\n",
    "    if word in explanation:\n",
    "        exp_score -= 1.0\n",
    "    guess_score = 0.\n",
    "    if len(explanation) > 0:\n",
    "        for pref in xrange(10):\n",
    "            guess = player2.guess(explanation[:pref + 1])[:10]\n",
    "            try:\n",
    "                pos = guess.index(word)\n",
    "                player1.explanation_result(pos)\n",
    "                player2.guess_result(pos)\n",
    "                guess_score += 0.9 ** pos\n",
    "                exp_score += 0.9 ** pos\n",
    "            except ValueError:\n",
    "                player1.explanation_result(None)\n",
    "                player2.guess_result(None)\n",
    "    return exp_score, guess_score\n",
    "\n",
    "\n",
    "def play(player1, player2, rounds, seed=42):\n",
    "    random_gen = np.random.RandomState(seed)\n",
    "    player1_exp_score = 0.\n",
    "    player1_guess_score = 0.\n",
    "    player2_exp_score = 0.\n",
    "    player2_guess_score = 0.\n",
    "    for _ in xrange(rounds):\n",
    "        word = random_gen.choice(words_universe)\n",
    "        player1_exp, player2_guess = calc_score(player1, player2, word)\n",
    "        player2_exp, player1_guess = calc_score(player2, player1, word)\n",
    "        player1_explanation = player1.explain(word)\n",
    "        player2_explanation = player1.explain(word)\n",
    "        \n",
    "        player1_exp_score += player1_exp\n",
    "        player2_exp_score += player2_exp\n",
    "        player1_guess_score += player1_guess\n",
    "        player2_guess_score += player2_guess\n",
    "        \n",
    "    return (\n",
    "        (player1_exp_score, player1_guess_score, player1_guess_score + player1_exp_score),\n",
    "        (player2_exp_score, player2_guess_score, player2_guess_score + player2_exp_score)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 1.69 s, total: 2min 48s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2627.0703817790027, 3238.650122383999, 5865.720504163002),\n",
       " (3238.650122383999, 2627.0703817790027, 5865.720504163002))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "play(mixed(), GensimHatPlayer(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches\n"
     ]
    }
   ],
   "source": [
    "text.similar('sdas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 18s, sys: 6.5 s, total: 8min 25s\n",
      "Wall time: 4min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((817.2088766669998, 869.6168147179999, 1686.8256913849996),\n",
       " (869.6168147179999, 817.2088766669998, 1686.8256913849996))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "play(mixed(), NltkHatPlayer(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.3 s, sys: 1.19 s, total: 49.5 s\n",
      "Wall time: 25.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((130.590049074, 135.362607879, 265.952656953),\n",
       " (135.362607879, 130.590049074, 265.952656953))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "play(GensimHatPlayer(), NltkHatPlayer(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
